~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Matrix Factorization~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Config: Namespace(ALPHA='0.3', BETA='0.5', CONV_KL=0.0001, CONV_LS=5e-06, CONV_MUL=0.0001, COST_F='LS', DATA_DIR='ppi', DELTA=1.0, ENF_Y=0, ETA='1.0', FACT_Y=1, FOLDER_SUFFIX='MNF_ppi_1.0_0.3_0.5_1.0_5.0_1.0_40_500', GAMMA='5.0', INIT='random', K='40', LAMBDA='1.0', LG=1, LOG_DIR='emb/Ppi/MNF_ppi_1.0_0.3_0.5_1.0_5.0_1.0_40_500', LOG_FNAME='mod_mnf.log', L_COMPONENTS=128, MAX_ITER='500', MODEL='data/', MULTI_LABEL=True, PHI=1.0, PROJ=True, THETA='1.0', ZETA=1000000000.0)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
================ Dataset Details : Start ================
Dataset: ppi
Attributes: ['view.mat']
Relations: ['adjmat.mat']
Sets: [50]
N_Folds: 5
Number of nodes : 3890
Number of labels : 50
Number of features : [444]
All label distribution : [ 0.00496988  0.00768072  0.02710843  0.02650602  0.01415663  0.02921687
  0.025       0.02680723  0.02740964  0.02831325  0.02560241  0.00466867
  0.02846386  0.02665663  0.00707831  0.02786145  0.01355422  0.0121988
  0.0251506   0.02063253  0.01671687  0.01069277  0.02846386  0.02228916
  0.00451807  0.02966867  0.02198795  0.02756024  0.0123494   0.01686747
  0.02861446  0.02650602  0.00828313  0.02981928  0.02756024  0.01385542
  0.01987952  0.02319277  0.01415663  0.02665663  0.02771084  0.02695783
  0.01506024  0.02936747  0.00512048  0.02605422  0.00557229  0.02213855
  0.0186747   0.00466867]
================ Dataset Details : End ================
% of randomly sampled training data ----  50
Performance_using_LR : Test accuracy: {0.01748 } , Test Loss: {0.74085 } Iter: {499}
Performance_using_SVM : Test accuracy: {0.01748 } , Test Loss: {0.74085 } Iter: {499}
Performance_without_classifier : Test accuracy: {0.00668 } , Test Loss: {0.75861 } Iter: {499}
**********************************************************
LR --->  [{'cross_entropy': 0.14817046284784266, 'macro_f1': 0.0047732592560488915, 'macro_precision': 0.0031531131741135434, 'accuracy': 0.003496143958868895, 'micro_precision': 0.012128489939318978, 'average_precision': 0.025833271746675622, 'macro_recall': 0.0098185938709040195, 'micro_f1': 0.012128389940143475, 'coverage': 4.7003598971722367, 'bae': 0.0, 'pak': array([ 0.,  0.,  0.,  0.]), 'hamming_loss': 0.012869922879177379, 'micro_recall': 0.012128489939318978, 'ranking_loss': 0.077022133083790162}]
SVM --->  [{'cross_entropy': 0.14817046284784266, 'macro_f1': 0.0047732592560488915, 'macro_precision': 0.0031531131741135434, 'accuracy': 0.003496143958868895, 'micro_precision': 0.012128489939318978, 'average_precision': 0.025833271746675622, 'macro_recall': 0.0098185938709040195, 'micro_f1': 0.012128389940143475, 'coverage': 4.7003598971722367, 'bae': 0.0, 'pak': array([ 0.,  0.,  0.,  0.]), 'hamming_loss': 0.012869922879177379, 'micro_recall': 0.012128489939318978, 'ranking_loss': 0.077022133083790162}]
N --->  [{'cross_entropy': 0.15172200380143899, 'macro_f1': 0.0083497340517170691, 'macro_precision': 0.0065551686707514311, 'accuracy': 0.0013367609254498715, 'micro_precision': 0.0076253377341262878, 'average_precision': 0.017620203258725479, 'macro_recall': 0.01149761525585875, 'micro_f1': 0.0076252377354376873, 'coverage': 6.0829820051413881, 'bae': 0.0, 'pak': array([ 0.,  0.,  0.,  0.]), 'hamming_loss': 0.01317840616966581, 'micro_recall': 0.0076253377341262878, 'ranking_loss': 0.10295564027540924}]

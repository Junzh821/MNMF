~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Matrix Factorization~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Config: Namespace(ALPHA='7.0', BETA='2.0', CONV_KL=0.0001, CONV_LS=7e-05, CONV_MUL=0.0001, COST_F='5e-05', DATA_DIR='../Datasets/ppi', DELTA=1.0, ENF_Y=0, ETA='1.0', FACT_Y=1, GAMMA=1.0, INIT='nndsvd', K='11', LAMBDA='1.0', LG=1, LOG_DIR='Results/L_ppi_1.0_7.0_2.0_7.0_1.0_1.0_128_11_5e-05/L_ppi_1.0_7.0_2.0_7.0_1.0_1.0_128_11_5e-05', LOG_FNAME='mod_mnmf.log', L_COMPONENTS='128', MAX_ITER=700, MULTI_LABEL=True, PHI='1.0', PROJ=True, THETA='7.0', ZETA=1000000000.0)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
================ Dataset Details : Start ================
Dataset: ppi
Attributes: ['view.mat']
Relations: ['adjmat.mat']
Sets: [10 30 50 70]
N_Folds: 5
Number of nodes : 3890
Number of labels : 50
Number of features : [444]
All label distribution : [  33.   51.  180.  176.   94.  194.  166.  178.  182.  188.  170.   31.
  189.  177.   47.  185.   90.   81.  167.  137.  111.   71.  189.  148.
   30.  197.  146.  183.   82.  112.  190.  176.   55.  198.  183.   92.
  132.  154.   94.  177.  184.  179.  100.  195.   34.  173.   37.  147.
  124.   31.]
================ Dataset Details : End ================
% of randomly sampled training data ----  10
Performance_using_classifier : Test accuracy: {0.04884 } , Test Loss: {0.69433 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.05784 } , Test Loss: {0.67894 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.03985 } , Test Loss: {0.70202 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.02956 } , Test Loss: {0.68722 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.03470 } , Test Loss: {0.68900 }
**********************************************************
[{'accuracy': 0.042159383033419026, 'micro_f1': 0.11785123970118942, 'micro_recall': 0.11785173969905313, 'micro_precision': 0.11785173969905313, 'macro_f1': 0.091114211178221244, 'coverage': 22.343701799485864, 'pak': array([ 0.,  0.,  0.]), 'cross_entropy': 0.69030198854706892, 'ranking_loss': 0.35351844700683499, 'macro_precision': 0.099922925252924372, 'bae': 0.0, 'average_precision': 0.18178104449203097, 'macro_recall': 0.084998765518336142, 'hamming_loss': 0.059958868894601544}]
% of randomly sampled training data ----  30
Performance_using_classifier : Test accuracy: {0.07584 } , Test Loss: {0.66887 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.06684 } , Test Loss: {0.67006 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.06812 } , Test Loss: {0.65822 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.06298 } , Test Loss: {0.66118 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.06041 } , Test Loss: {0.66473 }
**********************************************************
[{'accuracy': 0.066838046272493568, 'micro_f1': 0.16083657013545979, 'micro_recall': 0.1608370701339035, 'micro_precision': 0.1608370701339035, 'macro_f1': 0.13780188915796884, 'coverage': 20.566066838046272, 'pak': array([  0.00000000e+00,   8.56898029e-05,   5.14138817e-05]), 'cross_entropy': 0.66461247876903928, 'ranking_loss': 0.32073192041972209, 'macro_precision': 0.15514450632913812, 'bae': 0.0, 'average_precision': 0.22256454958578548, 'macro_recall': 0.12586934110349174, 'hamming_loss': 0.05772750642673522}]
% of randomly sampled training data ----  50
Performance_using_classifier : Test accuracy: {0.10283 } , Test Loss: {0.64461 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.09512 } , Test Loss: {0.63691 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.09254 } , Test Loss: {0.64520 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.10283 } , Test Loss: {0.63395 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.10283 } , Test Loss: {0.63691 }
**********************************************************
[{'accuracy': 0.099228791773778927, 'micro_f1': 0.17463662744632455, 'micro_recall': 0.1746371274448914, 'micro_precision': 0.1746371274448914, 'macro_f1': 0.14337079400419303, 'coverage': 19.279948586118252, 'pak': array([ 0.,  0.,  0.]), 'cross_entropy': 0.63951489317955823, 'ranking_loss': 0.29748520413748158, 'macro_precision': 0.15311912596158556, 'bae': 0.0, 'average_precision': 0.2538016374220437, 'macro_recall': 0.13524787390911253, 'hamming_loss': 0.05554755784061697}]
% of randomly sampled training data ----  70
Performance_using_classifier : Test accuracy: {0.09512 } , Test Loss: {0.63040 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.08612 } , Test Loss: {0.63454 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.09254 } , Test Loss: {0.63040 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.09254 } , Test Loss: {0.62862 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.09769 } , Test Loss: {0.62270 }
**********************************************************
[{'accuracy': 0.092802056555269921, 'micro_f1': 0.1914823895895324, 'micro_recall': 0.19148288958822593, 'micro_precision': 0.19148288958822593, 'macro_f1': 0.16560128292388332, 'coverage': 19.189460154241644, 'pak': array([ 0.,  0.,  0.]), 'cross_entropy': 0.62933379713849646, 'ranking_loss': 0.29756472083351049, 'macro_precision': 0.18090836564542512, 'bae': 0.0, 'average_precision': 0.26134916578684164, 'macro_recall': 0.15339680960707403, 'hamming_loss': 0.05466323907455013}]

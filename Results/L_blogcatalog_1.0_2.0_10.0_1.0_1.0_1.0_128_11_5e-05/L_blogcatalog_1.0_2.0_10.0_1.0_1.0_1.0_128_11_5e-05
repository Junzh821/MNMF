~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Matrix Factorization~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Config: Namespace(ALPHA='2.0', BETA='10.0', CONV_KL=0.0001, CONV_LS=7e-05, CONV_MUL=0.0001, COST_F='5e-05', DATA_DIR='../Datasets/blogcatalog', DELTA=1.0, ENF_Y=0, ETA='1.0', FACT_Y=1, GAMMA='1.0', INIT='nndsvd', K='11', LAMBDA='1.0', LG=1, LOG_DIR='Results/L_blogcatalog_1.0_2.0_10.0_1.0_1.0_1.0_128_11_5e-05/L_blogcatalog_1.0_2.0_10.0_1.0_1.0_1.0_128_11_5e-05', LOG_FNAME='mod_mnmf.log', L_COMPONENTS='128', MAX_ITER=700, MULTI_LABEL=True, PHI=3.0, PROJ=True, THETA='1.0', ZETA=1000000000.0)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
================ Dataset Details : Start ================
Dataset: blogcatalog
Attributes: ['view.mat']
Relations: ['adjmat.mat']
Sets: [10 30 50 70]
N_Folds: 5
Number of nodes : 10312
Number of labels : 39
Number of features : [444]
All label distribution : [  167.   778.   619.   246.   908.   876.   610.  1623.   323.   405.
   472.    38.   514.   306.    91.   415.   467.   311.   986.   320.
   246.   287.   325.   977.   201.   284.    94.   112.   173.   372.
    98.   386.    95.    64.    62.   137.    53.    27.     8.]
================ Dataset Details : End ================
% of randomly sampled training data ----  10
Performance_using_classifier : Test accuracy: {0.14985 } , Test Loss: {0.65397 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.15955 } , Test Loss: {0.64710 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.15907 } , Test Loss: {0.64509 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.15858 } , Test Loss: {0.64366 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.15713 } , Test Loss: {0.64338 }
**********************************************************
[{'micro_recall': 0.23340122191670018, 'hamming_loss': 0.056166529881369845, 'ranking_loss': 0.23063056239456731, 'macro_f1': 0.095115572473914931, 'micro_precision': 0.23340122191670018, 'macro_recall': 0.079661917000207347, 'bae': 0.0, 'micro_f1': 0.23340072191777175, 'accuracy': 0.1568380213385063, 'average_precision': 0.34667017813935941, 'cross_entropy': 0.64664107214937905, 'coverage': 11.60368574199806, 'macro_precision': 0.11943130782009621, 'pak': array([ 0.,  0.,  0.])}]
% of randomly sampled training data ----  30
Performance_using_classifier : Test accuracy: {0.18235 } , Test Loss: {0.62906 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.18623 } , Test Loss: {0.62763 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.18138 } , Test Loss: {0.63135 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.17992 } , Test Loss: {0.63278 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.17847 } , Test Loss: {0.63421 }
**********************************************************
[{'micro_recall': 0.2569790963395216, 'hamming_loss': 0.05480862493471611, 'ranking_loss': 0.21607466058291927, 'micro_precision': 0.2569790963395216, 'macro_recall': 0.096386213367070414, 'pak': array([ 0.,  0.,  0.]), 'bae': 0.0, 'micro_f1': 0.25697859634049453, 'average_precision': 0.3780232309357599, 'macro_precision': 0.15853883636094959, 'cross_entropy': 0.6310076137099474, 'coverage': 10.964015518913678, 'macro_f1': 0.11987050183349657, 'accuracy': 0.18166828322017459}]
% of randomly sampled training data ----  50
Performance_using_classifier : Test accuracy: {0.20951 } , Test Loss: {0.59814 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.20951 } , Test Loss: {0.59671 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.21872 } , Test Loss: {0.59585 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.21823 } , Test Loss: {0.59098 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.21532 } , Test Loss: {0.59585 }
**********************************************************
[{'micro_recall': 0.27884882098514263, 'hamming_loss': 0.05172473824268198, 'ranking_loss': 0.21075903689147957, 'macro_f1': 0.13001452962259424, 'micro_precision': 0.27884882098514263, 'macro_recall': 0.10671626977661448, 'bae': 0.0, 'micro_f1': 0.27884832098603923, 'accuracy': 0.21425800193986419, 'average_precision': 0.39889202622840303, 'cross_entropy': 0.59550305608209286, 'coverage': 10.729582929194956, 'macro_precision': 0.16703242066505894, 'pak': array([ 0.,  0.,  0.])}]
% of randomly sampled training data ----  70
Performance_using_classifier : Test accuracy: {0.21823 } , Test Loss: {0.60558 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.21775 } , Test Loss: {0.60558 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.21629 } , Test Loss: {0.60644 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.21920 } , Test Loss: {0.60644 }
**********************************************************
Performance_using_classifier : Test accuracy: {0.21872 } , Test Loss: {0.60329 }
**********************************************************
[{'micro_recall': 0.28897108261971383, 'hamming_loss': 0.05259021612076897, 'ranking_loss': 0.20218398438957291, 'micro_precision': 0.28897108261971383, 'macro_recall': 0.1146596227664491, 'pak': array([ 0.,  0.,  0.]), 'bae': 0.0, 'micro_f1': 0.28897058262057895, 'average_precision': 0.40683041178959656, 'macro_precision': 0.19315842058856733, 'cross_entropy': 0.60546723838402039, 'coverage': 10.462851600387973, 'macro_f1': 0.14374580161085224, 'accuracy': 0.21804073714839961}]
